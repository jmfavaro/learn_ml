---
title: "ISLR Notebook"
output:
  html_notebook: default
  pdf_document: default
---

Notebook pour le livre "Introduction to Statistical Learning with Applications in R" 
(url)[http://www-bcf.usc.edu/~gareth/ISL/]

MOOC : https://lagunita.stanford.edu/dashboard

id : jmfavaro@yahoo.fr  
pwd : JM70vinn




```{r}
library(ISLR)
```
```{python}
np = [1,2,3]
print(np)
print(type(np))
```

# Chapitre 2 : Statistical Learning

- prédiction **vs** l'inférence

- methode paramétrique **vs** non-paramétrique : la forme de **f** est défini vs la forme ne l'est pas.
les méthodes non paramétriques sont généralement utilisés pour la prédiction car meilleure pour ça. cela dit, pas toujours car ces méthodes sont sensibles à l'*overfitting*.

- supervised **vs** unsupervised 

- regression **vs** classification pb : selon le type de variable à modéliser (quant ou quali). 

## Assessing model accuracy

### regression settings

pour la regression : MSE. calcul pour le training dataset et le test dataset.
overfitting : le training est très faible mais le test est fort
=> cross validation

- the bias-variance trade off

expected test MSE se décompose en 3 parties:
    - variance
    - squared biais
    - variance de l'erreur
    
la variance : variation du à l'échantillon (on change d'échantillon, on a des coef un peu différents). plus la methode stat est flexible, plus la variance est forte en général.
biais : provient des simplifications faites sur la forme fonctionnelle (un mod lin peut avoir un très fort biais si la relation n'est pas linéaire). plus un mothode est flexible, moins le biais est fort (en général).
donc plus la methode est flexible, plus la variance augmente et plus le biais baisse. la point critique est la dynamique des 2.

ce trade-off est la principale difficulté. il ne faut jamais le perdre de vue. Il se manifeste par la courbe en U du taux d'erreur sur le test dataset.




### classification settings

- error rate

#### the bayes classifier:  affecter à la classe qui a la plus forte probabilité

- Bayes decision boundary : limite (frontiere) séparant les classes via le bayes classifier

- le bayes classifier produit le plus petit taux d'erreur (error rate), appelé le **bayes error rate**

#### K-Nearest Neighbors (KNN)

En theorie, on voudrait toujours utiliser le bayes classifier, mais en pratique, on on ne connait pas la distribution conditionnelle de Y sachant X. donc on peut pas le calculer (*?? pourquoi*)

Souvent très proche du bayes classifier. le choix de K joue énormément. Si K=1, modèle très flexible (overfitting), plus K grandit, moins le modèle est flexible et la frontière devient linéaire. Il n'y a pas de relation forte entre le taux d'erreur sur le training et le test dataset.
















